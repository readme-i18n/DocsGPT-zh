---

title: DocsGPT 的 Docker 部署
description: 使用 Docker 和 Docker Compose 轻松部署和管理 DocsGPT。
---

# DocsGPT 的 Docker 部署

Docker 是部署 DocsGPT 的推荐方式，能为应用提供一致的隔离运行环境。本指南将引导您使用 Docker 和 Docker Compose 完成部署。

## 前置条件

* **Docker 引擎:** 系统需安装 Docker 引擎
    * **macOS:** [Docker Desktop for Mac](https://docs.docker.com/desktop/install/mac-install/)
    * **Linux:** [Docker 引擎安装指南](https://docs.docker.com/engine/install/) (根据具体发行版选择安装方式)
    * **Windows:** [Docker Desktop for Windows](https://docs.docker.com/desktop/install/windows-install/) (需 WSL 2 支持，详见下方说明)
* **Docker Compose:** Docker Desktop 通常已包含该组件。若单独使用 Docker 引擎，请确保安装 Docker Compose V2

**Windows 用户重要提示:** Windows 上的 Docker Desktop 通常需要 WSL 2 后端支持才能正常运行，特别是当使用 DocsGPT 的 Docker Compose 配置中涉及的 host 网络等功能时。请确保在 Docker Desktop 设置中启用并配置 WSL 2。

## 最快捷方案：使用 DocsGPT 公共 API

体验 DocsGPT 最快的方式是使用公共 API 端点。这种方式配置极简且无需本地 LLM 设置。

1.  **克隆 DocsGPT 仓库（如尚未操作）：**

    ```bash
    git clone https://github.com/arc53/DocsGPT.git
    cd DocsGPT
    ```

2.  **创建 `.env` 文件：**

    在 DocsGPT 仓库的根目录下创建名为 `.env` 的文件。

3.  **向 `.env` 添加公共 API 配置：**

    打开 `.env` 文件并添加以下内容：

    ```
    LLM_PROVIDER=docsgpt
    VITE_API_STREAMING=true
    ```

    此最小化配置告知 DocsGPT 使用公共 API。如需高级设置和其他 LLM 选项，请参阅 [DocsGPT 设置指南](/Deploying/DocsGPT-Settings)。

4.  **使用 Docker Compose 启动 DocsGPT：**

    在终端中导航至 DocsGPT 仓库的根目录并运行：

    ```bash
    docker compose -f deployment/docker-compose.yaml up -d
    ```

    `-d` 标志表示以分离模式（后台运行）启动 Docker Compose。

5.  **在浏览器中访问 DocsGPT：**

    当容器运行后，打开浏览器访问 [http://localhost:5173/](http://localhost:5173/)。

6.  **停止 DocsGPT：**

    要停止应用，在终端中进入相同目录并运行：

    ```bash
    docker compose -f deployment/docker-compose.yaml down
    ```

## 可选的 Ollama 设置（本地模型）

DocsGPT 提供了可选的 Docker Compose 文件，便于与 [Ollama](https://ollama.com/) 集成以运行本地模型。这些文件会在您的 Docker Compose 配置中添加一个官方的 Ollama 容器。相关文件位于 `deployment/optional/` 目录下。

Ollama 可选文件包含两种：

*   **`docker-compose.optional.ollama-cpu.yaml`**：用于在 CPU 上运行 Ollama
*   **`docker-compose.optional.ollama-gpu.yaml`**：用于在 GPU 上运行 Ollama（需要预先配置 Docker 的 GPU 支持）

### 启动 Ollama 并拉取模型

1. **克隆 DocsGPT 仓库并创建 `.env` 文件（如上文所述）**

2. **使用 Ollama Docker Compose 启动 DocsGPT：**

   选择适合的 Ollama Compose 文件（CPU 或 GPU 版本）并启动 DocsGPT：

   **CPU 版本：**
   ```bash
   docker compose --env-file .env -f deployment/docker-compose.yaml -f deployment/optional/docker-compose.optional.ollama-cpu.yaml up -d
   ```
   **GPU 版本：**
   ```bash
   docker compose --env-file .env -f deployment/docker-compose.yaml -f deployment/optional/docker-compose.optional.ollama-gpu.yaml up -d
   ```

3. **拉取 Ollama 模型：**

   **关键步骤：** 使用 Ollama 启动后，需将所需模型拉取至 Ollama 容器内。在 `.env` 文件中找到配置的 `LLM_NAME`（例如 `llama3.2:1b`），然后在运行的 Ollama 容器内执行以下命令拉取模型：

   ```bash
   docker compose -f deployment/docker-compose.yaml -f deployment/optional/docker-compose.optional.ollama-cpu.yaml exec -it ollama ollama pull <LLM_NAME>
   ```
   或（GPU 版本）：
   ```bash
   docker compose -f deployment/docker-compose.yaml -f deployment/optional/docker-compose.optional.ollama-gpu.yaml exec -it ollama ollama pull <LLM_NAME>
   ```
   将 `<LLM_NAME>` 替换为 `.env` 文件中的实际模型名称。

4. **在浏览器中访问 DocsGPT：**

   模型拉取完成且容器运行后，打开浏览器访问 [http://localhost:5173/](http://localhost:5173/)。

5. **停止 Ollama 服务：**

   若要停止通过 Ollama 可选文件启动的 DocsGPT 服务，需在 `docker compose down` 命令中包含所有 `up` 阶段使用的 compose 文件：

   ```bash
   docker compose -f deployment/docker-compose.yaml -f deployment/optional/docker-compose.optional.ollama-cpu.yaml down
   ```
   或
   ```bash
   docker compose -f deployment/docker-compose.yaml -f deployment/optional/docker-compose.optional.ollama-gpu.yaml down
   ```

**GPU 使用注意事项：**

*   **NVIDIA 容器工具包（适用于 NVIDIA GPU）：** 若使用 NVIDIA GPU，需在系统中安装并配置 [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)，以便 Docker 访问 GPU 资源。
*   **Docker GPU 配置：** 确保 Docker 已配置为使用 GPU。请参考 [Ollama Docker Hub 页面](https://hub.docker.com/r/ollama/ollama) 及 Docker 官方文档，根据您的 GPU 类型（NVIDIA/AMD/Intel）进行具体设置。

## 配置变更后重启服务

修改 `.env` 文件或任何 Docker Compose 文件后，必须重启 Docker 容器才能使变更生效。使用最初启动 DocsGPT 时相同的命令 `docker compose down` 和 `docker compose up -d`，若使用了可选配置文件，请确保包含所有对应的 `-f` 参数。

## 进阶配置

本文档仅涵盖 DocsGPT 的 Docker 基础部署。如需配置 LLM 供应商、模型、向量存储等高级选项，请参阅完整的 [DocsGPT 设置指南](/Deploying/DocsGPT-Settings)。